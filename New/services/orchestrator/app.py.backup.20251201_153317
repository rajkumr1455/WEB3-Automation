"""
Orchestrator Service
Central pipeline controller that coordinates all agents sequentially
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import Optional, Dict, Any, List
import httpx
import os
import logging
import json
import uuid
from datetime import datetime
from enum import Enum
from prometheus_client import Counter, Histogram, Gauge, generate_latest
from fastapi.responses import Response
import asyncio

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Prometheus metrics
SCAN_COUNT = Counter('orchestrator_scans_total', 'Total scans', ['status'])
SCAN_DURATION = Histogram('orchestrator_scan_duration_seconds', 'Scan duration')
ACTIVE_SCANS = Gauge('orchestrator_active_scans', 'Currently active scans')
AGENT_ERRORS = Counter('orchestrator_agent_errors_total', 'Agent errors', ['agent'])

app = FastAPI(title="Web3 Bounty Orchestrator", version="1.0.0")

# Configure CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3001",  # Next.js UI
        "http://localhost:3000",  # Grafana
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Agent URLs from environment
AGENT_URLS = {
    "llm_router": os.getenv("LLM_ROUTER_URL", "http://llm-router:8000"),
    "recon": os.getenv("RECON_AGENT_URL", "http://recon-agent:8002"),
    "static": os.getenv("STATIC_AGENT_URL", "http://static-agent:8003"),
    "fuzzing": os.getenv("FUZZING_AGENT_URL", "http://fuzzing-agent:8004"),
    "monitoring": os.getenv("MONITORING_AGENT_URL", "http://monitoring-agent:8005"),
    "triage": os.getenv("TRIAGE_AGENT_URL", "http://triage-agent:8006"),
    "reporting": os.getenv("REPORTING_AGENT_URL", "http://reporting-agent:8007"),
}

# In-memory scan storage (use Redis/DB in production)
scans_db: Dict[str, Dict[str, Any]] = {}


class ScanStatus(str, Enum):
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"


class ScanRequest(BaseModel):
    """Request to start a new security scan"""
    target_url: str = Field(..., description="Target repository or contract URL")
    contract_address: Optional[str] = Field(None, description="Smart contract address (if applicable)")
    chain: Optional[str] = Field("ethereum", description="Blockchain network")
    scan_config: Optional[Dict[str, Any]] = Field(default_factory=dict, description="Custom scan configuration")


class ScanResponse(BaseModel):
    """Response for scan request"""
    scan_id: str
    status: ScanStatus
    message: str


class ScanResult(BaseModel):
    """Complete scan result"""
    scan_id: str
    status: ScanStatus
    target_url: str
    contract_address: Optional[str]
    started_at: str
    completed_at: Optional[str]
    duration_seconds: Optional[float]
    results: Optional[Dict[str, Any]]
    error: Optional[str]


async def call_agent(agent_name: str, endpoint: str, data: Dict[str, Any], timeout: int = 300) -> Dict[str, Any]:
    """Call an agent service"""
    url = f"{AGENT_URLS[agent_name]}{endpoint}"
    
    try:
        logger.info(f"Calling {agent_name} agent at {url}")
        async with httpx.AsyncClient(timeout=timeout) as client:
            response = await client.post(url, json=data)
            response.raise_for_status()
            return response.json()
    except Exception as e:
        AGENT_ERRORS.labels(agent=agent_name).inc()
        logger.error(f"{agent_name} agent failed: {e}")
        raise


async def run_scan_pipeline(scan_id: str, request: ScanRequest):
    """Execute the complete security scan pipeline"""
    start_time = datetime.now()
    
    try:
        ACTIVE_SCANS.inc()
        scans_db[scan_id]["status"] = ScanStatus.RUNNING
        scans_db[scan_id]["progress"] = 0
        
        # Stage 1: Reconnaissance
        logger.info(f"[{scan_id}] Stage 1: Reconnaissance")
        scans_db[scan_id]["current_stage"] = "recon"
        scans_db[scan_id]["progress"] = 10
        recon_result = await call_agent("recon", "/scan", {
            "target_url": request.target_url,
            "contract_address": request.contract_address,
            "chain": request.chain
        })
        scans_db[scan_id]["results"]["recon"] = recon_result
        scans_db[scan_id]["progress"] = 30
        
        # Stage 2: Static Analysis
        logger.info(f"[{scan_id}] Stage 2: Static Analysis")
        scans_db[scan_id]["current_stage"] = "static"
        scans_db[scan_id]["progress"] = 35
        static_result = await call_agent("static", "/analyze", {
            "scan_id": scan_id,
            "contracts": recon_result.get("contracts", []),
            "source_code": recon_result.get("source_code", {})
        })
        scans_db[scan_id]["results"]["static"] = static_result
        scans_db[scan_id]["progress"] = 50
        
        # Stage 3: Fuzzing (if applicable)
        if recon_result.get("contracts") and request.scan_config.get("enable_fuzzing", True):
            logger.info(f"[{scan_id}] Stage 3: Fuzzing")
            scans_db[scan_id]["current_stage"] = "fuzzing"
            fuzzing_result = await call_agent("fuzzing", "/fuzz", {
                "scan_id": scan_id,
                "contracts": recon_result.get("contracts", []),
                "abis": recon_result.get("abis", [])
            }, timeout=600)  # Longer timeout for fuzzing
            scans_db[scan_id]["results"]["fuzzing"] = fuzzing_result
        else:
            logger.info(f"[{scan_id}] Stage 3: Fuzzing skipped")
            scans_db[scan_id]["results"]["fuzzing"] = {"skipped": True}
        scans_db[scan_id]["progress"] = 65
        
        # Stage 4: Dynamic Monitoring (if contract address provided)
        if request.contract_address:
            logger.info(f"[{scan_id}] Stage 4: Dynamic Monitoring")
            scans_db[scan_id]["current_stage"] = "monitoring"
            monitoring_result = await call_agent("monitoring", "/monitor", {
                "scan_id": scan_id,
                "contract_address": request.contract_address,
                "chain": request.chain,
                "duration_minutes": request.scan_config.get("monitor_duration", 5)
            })
            scans_db[scan_id]["results"]["monitoring"] = monitoring_result
        else:
            logger.info(f"[{scan_id}] Stage 4: Monitoring skipped (no contract address)")
            scans_db[scan_id]["results"]["monitoring"] = {"skipped": True}
        scans_db[scan_id]["progress"] = 75
        
        # Stage 5: Triage
        logger.info(f"[{scan_id}] Stage 5: Triage")
        scans_db[scan_id]["current_stage"] = "triage"
        scans_db[scan_id]["progress"] = 80
        triage_result = await call_agent("triage", "/triage", {
            "scan_id": scan_id,
            "findings": {
                "static": scans_db[scan_id]["results"]["static"],
                "fuzzing": scans_db[scan_id]["results"]["fuzzing"],
                "monitoring": scans_db[scan_id]["results"]["monitoring"]
            }
        })
        scans_db[scan_id]["results"]["triage"] = triage_result
        scans_db[scan_id]["progress"] = 90
        
        # Stage 6: Reporting
        logger.info(f"[{scan_id}] Stage 6: Reporting")
        scans_db[scan_id]["current_stage"] = "reporting"
        scans_db[scan_id]["progress"] = 95
        reporting_result = await call_agent("reporting", "/generate", {
            "scan_id": scan_id,
            "target_url": request.target_url,
            "contract_address": request.contract_address,
            "findings": scans_db[scan_id]["results"]
        })
        scans_db[scan_id]["results"]["reporting"] = reporting_result
        
        # Mark as completed
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()
        
        scans_db[scan_id].update({
            "status": ScanStatus.COMPLETED,
            "completed_at": end_time.isoformat(),
            "duration_seconds": duration,
            "current_stage": "completed",
            "progress": 100
        })
        
        SCAN_COUNT.labels(status="completed").inc()
        SCAN_DURATION.observe(duration)
        
        logger.info(f"[{scan_id}] Scan completed in {duration:.2f}s")
        
    except Exception as e:
        logger.error(f"[{scan_id}] Scan failed: {e}")
        scans_db[scan_id].update({
            "status": ScanStatus.FAILED,
            "error": str(e),
            "completed_at": datetime.now().isoformat()
        })
        SCAN_COUNT.labels(status="failed").inc()
    
    finally:
        ACTIVE_SCANS.dec()


@app.post("/scan", response_model=ScanResponse)
async def start_scan(request: ScanRequest, background_tasks: BackgroundTasks):
    """Start a new security scan"""
    scan_id = str(uuid.uuid4())
    
    # Initialize scan record
    scans_db[scan_id] = {
        "scan_id": scan_id,
        "status": ScanStatus.PENDING,
        "target_url": request.target_url,
        "contract_address": request.contract_address,
        "chain": request.chain,
        "started_at": datetime.now().isoformat(),
        "completed_at": None,
        "current_stage": "pending",
        "progress": 0,
        "results": {},
        "error": None
    }
    
    # Start pipeline in background
    background_tasks.add_task(run_scan_pipeline, scan_id, request)
    
    logger.info(f"Started scan {scan_id} for {request.target_url}")
    
    return ScanResponse(
        scan_id=scan_id,
        status=ScanStatus.PENDING,
        message=f"Scan started successfully. Use /scan/{scan_id} to check status."
    )


@app.get("/scan/{scan_id}", response_model=ScanResult)
async def get_scan(scan_id: str):
    """Get scan status and results"""
    if scan_id not in scans_db:
        raise HTTPException(status_code=404, detail="Scan not found")
    
    scan = scans_db[scan_id]
    
    return ScanResult(
        scan_id=scan["scan_id"],
        status=scan["status"],
        target_url=scan["target_url"],
        contract_address=scan.get("contract_address"),
        started_at=scan["started_at"],
        completed_at=scan.get("completed_at"),
        duration_seconds=scan.get("duration_seconds"),
        results=scan.get("results") if scan["status"] == ScanStatus.COMPLETED else None,
        error=scan.get("error")
    )


@app.get("/scans")
async def list_scans(limit: int = 50, status: Optional[ScanStatus] = None):
    """List recent scans"""
    scans = list(scans_db.values())
    
    if status:
        scans = [s for s in scans if s["status"] == status]
    
    # Sort by start time (most recent first)
    scans.sort(key=lambda x: x["started_at"], reverse=True)
    
    return {
        "total": len(scans),
        "scans": scans[:limit]
    }


@app.get("/health")
async def health():
    """Health check endpoint"""
    # Check agent connectivity
    agent_health = {}
    
    async with httpx.AsyncClient(timeout=5) as client:
        for agent_name, url in AGENT_URLS.items():
            try:
                response = await client.get(f"{url}/health")
                agent_health[agent_name] = "healthy" if response.status_code == 200 else "unhealthy"
            except:
                agent_health[agent_name] = "unreachable"
    
    all_healthy = all(status == "healthy" for status in agent_health.values())
    
    return {
        "status": "healthy" if all_healthy else "degraded",
        "agents": agent_health,
        "active_scans": len([s for s in scans_db.values() if s["status"] == ScanStatus.RUNNING])
    }


@app.get("/metrics")
async def metrics():
    """Prometheus metrics endpoint"""
    return Response(content=generate_latest(), media_type="text/plain")


# ===== Address Scanner Proxy Endpoints =====
@app.get("/address-scanner/supported-chains")
async def proxy_supported_chains():
    """Proxy endpoint for address-scanner supported chains"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.get(
                "http://address-scanner:8008/supported-chains",
                timeout=10.0
            )
            return response.json()
    except Exception as e:
        logger.error(f"Failed to fetch supported chains: {e}")
        raise HTTPException(status_code=503, detail="Address scanner service unavailable")


@app.post("/address-scanner/scan-address")
async def proxy_scan_address(request: Dict[str, Any]):
    """Proxy endpoint for address-scanner scan requests"""
    try:
        async with httpx.AsyncClient() as client:
            response = await client.post(
                "http://address-scanner:8008/scan-address",
                json=request,
                timeout=180.0  # 3 minutes for scan timeout
            )
            
            if response.status_code != 200:
                error_detail = response.json().get('detail', 'Scan failed')
                raise HTTPException(status_code=response.status_code, detail=error_detail)
            
            return response.json()
    except httpx.TimeoutException:
        raise HTTPException(status_code=504, detail="Address scan timed out")
    except httpx.ConnectError:
        logger.error("Cannot connect to address-scanner service")
        raise HTTPException(status_code=503, detail="Address scanner service unavailable")
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"Failed to scan address: {e}")
        raise HTTPException(status_code=500, detail=f"Address scan failed: {str(e)}")


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=8001)
